{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0960f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b217ac",
   "metadata": {},
   "source": [
    "PROBLEM 1: Data analysis using markov chians \n",
    "\n",
    "In this problem, you will empirically analyze a Markov chain \n",
    "with a finite state space. Transition probabilities are unknown.\n",
    "\n",
    "The state space is:\n",
    "    S = {0, 1, 2, 3}\n",
    "\n",
    "You are given the data for the observed X_t for t  = 0..19\n",
    "\n",
    "Tasks:\n",
    "1. Estimate the transition matrix P from the observed transitions.\n",
    "2. Verify that the estimated matrix is a probability transition matrix.\n",
    "3. Compute the stationary distribution pi of the chain.\n",
    "4. Simulate the chain using the estimated transition matrix\n",
    "5. Compute the expected hitting times via\n",
    "\n",
    "   (a) Simulation\n",
    "\n",
    "   (b) Solving linear equations (analytical hitting times). \n",
    "\n",
    "Compare the estimates and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a471499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# state space\n",
    "S = [0, 1, 2, 3]\n",
    "N_states = len(S)\n",
    "\n",
    "# Observed transitions: each row is (current_state, next_state)\n",
    "X_t = np.array([\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [3, 0],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [1, 3],\n",
    "    [3, 1],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 0],\n",
    "], dtype=int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22d60",
   "metadata": {},
   "source": [
    "Below are methods that you need to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b339dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1.1 Estimate transition matrix from observed transitions\n",
    "\n",
    "def comp_transition_matrix(transitions, n_states):\n",
    "    \"\"\"\n",
    "    Estimate the transition matrix P from observed transitions.\n",
    "\n",
    "    transitions : array of shape (n_samples, 2)\n",
    "        Each row contains (current_state, next_state)\n",
    "    n_states : int\n",
    "        Total number of states in the Markov chain\n",
    "\n",
    "    Returns:\n",
    "        P_hat : (n_states x n_states) numpy array\n",
    "            Empirical estimate of transition probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize matrix of transition counts\n",
    "    P_hat = np.zeros((n_states, n_states), dtype=float)\n",
    "\n",
    "    # Count how many times each transition i -> j occurs\n",
    "    for i, j in transitions:\n",
    "        P_hat[i, j] += 1.0\n",
    "\n",
    "    # Compute total outgoing transitions from each state i\n",
    "    row_sums = P_hat.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Normalize rows to convert counts into probabilities\n",
    "    # States with no outgoing transitions remain zero rows\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        P_hat = np.where(row_sums > 0, P_hat / row_sums, 0.0)\n",
    "\n",
    "    return P_hat\n",
    "\n",
    "\n",
    "# 1.2 Check if a matrix is a valid transition matrix\n",
    "\n",
    "def is_transition_matrix(P, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Check whether P is a valid Markov transition matrix.\n",
    "\n",
    "    Conditions:\n",
    "    1. P is square\n",
    "    2. All entries are non-negative\n",
    "    3. Each row sums to 1 (within numerical tolerance)\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "\n",
    "    # Check matrix is square\n",
    "    if P.ndim != 2 or P.shape[0] != P.shape[1]:\n",
    "        return False\n",
    "\n",
    "    # Check non-negativity (allow tiny numerical errors)\n",
    "    if np.any(P < -tol):\n",
    "        return False\n",
    "\n",
    "    # Each row must sum to 1\n",
    "    row_sums = P.sum(axis=1)\n",
    "    return np.all(np.abs(row_sums - 1.0) <= 1e-8)\n",
    "\n",
    "\n",
    "# 1.3 Compute stationary distribution\n",
    "\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute a stationary distribution pi such that:\n",
    "\n",
    "        pi P = pi\n",
    "        sum(pi) = 1\n",
    "        pi_i >= 0\n",
    "\n",
    "    Uses the eigenvector method with a linear-system fallback.\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of P^T\n",
    "    # Stationary distribution is a left eigenvector with eigenvalue 1\n",
    "    w, v = np.linalg.eig(P.T)\n",
    "\n",
    "    # Find eigenvalue closest to 1\n",
    "    idx = np.argmin(np.abs(w - 1.0))\n",
    "    pi = np.real(v[:, idx])\n",
    "\n",
    "    # Enforce non-negativity (eigenvectors are defined up to sign)\n",
    "    pi = np.where(pi < 0, -pi, pi)\n",
    "\n",
    "    # Normalize to make it a probability distribution\n",
    "    s = pi.sum()\n",
    "\n",
    "    if s == 0:\n",
    "        # Fallback: solve (P^T - I) pi = 0 with sum(pi) = 1\n",
    "        n = P.shape[0]\n",
    "        A = np.vstack([P.T - np.eye(n), np.ones(n)])\n",
    "        b = np.zeros(n + 1)\n",
    "        b[-1] = 1\n",
    "\n",
    "        pi, *_ = np.linalg.lstsq(A, b, rcond=None)\n",
    "        pi = np.maximum(pi, 0)\n",
    "        pi = pi / pi.sum()\n",
    "    else:\n",
    "        pi = pi / s\n",
    "\n",
    "    return pi\n",
    "\n",
    "\n",
    "# 1.4 Simulate a Markov chain trajectory\n",
    "\n",
    "def simulate_chain(P, start_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain path with a fixed random seed.\n",
    "\n",
    "    Returns:\n",
    "        path : array of length n_steps + 1\n",
    "            path[t] is the state at time t\n",
    "    \"\"\"\n",
    "\n",
    "    seed = 1234  # fixed seed for reproducibility\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    n_states = P.shape[0]\n",
    "\n",
    "    path = np.zeros(n_steps + 1, dtype=int)\n",
    "    path[0] = start_state\n",
    "\n",
    "    cur = start_state\n",
    "    for t in range(1, n_steps + 1):\n",
    "        # Sample next state using the transition probabilities\n",
    "        cur = rng.choice(n_states, p=P[cur])\n",
    "        path[t] = cur\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "# 1.5 Monte Carlo estimation of hitting times\n",
    "\n",
    "def hitting_times_sim(P, start_state, n_sim=10_000):\n",
    "    \"\"\"\n",
    "    Estimate expected hitting times E[T_{start -> j}] by simulation.\n",
    "\n",
    "    Convention:\n",
    "    - T_{j -> j} is the first return time (t >= 1)\n",
    "\n",
    "    Returns:\n",
    "        est[j] = estimated expected number of steps to hit state j\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    n_states = P.shape[0]\n",
    "\n",
    "    seed = 1234\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    est = np.full(n_states, np.nan, dtype=float)\n",
    "\n",
    "    for target in range(n_states):\n",
    "        times = np.empty(n_sim, dtype=float)\n",
    "\n",
    "        for s in range(n_sim):\n",
    "            cur = start_state\n",
    "            steps = 0\n",
    "\n",
    "            # Simulate until target is reached\n",
    "            while True:\n",
    "                cur = rng.choice(n_states, p=P[cur])\n",
    "                steps += 1\n",
    "                if cur == target:\n",
    "                    times[s] = steps\n",
    "                    break\n",
    "\n",
    "        est[target] = times.mean()\n",
    "\n",
    "    return est\n",
    "\n",
    "\n",
    "# 1.6 Analytical (theoretical) hitting times\n",
    "\n",
    "def theoretical_hitting_times(P, start_state):\n",
    "    \"\"\"\n",
    "    Compute expected hitting times analytically using linear equations.\n",
    "\n",
    "    For each target j:\n",
    "        m_i = E_i[T_j]\n",
    "        m_i = 1 + sum_{k != j} P[i,k] m_k\n",
    "\n",
    "    Returns:\n",
    "        hit_theor[j] = E_{start_state}[T_j]\n",
    "    \"\"\"\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    n_states = P.shape[0]\n",
    "\n",
    "    hit_theor = np.full(n_states, np.nan, dtype=float)\n",
    "\n",
    "    for target in range(n_states):\n",
    "\n",
    "        # Initialize system A m = b\n",
    "        A = np.eye(n_states)\n",
    "        b = np.ones(n_states)\n",
    "\n",
    "        # Build equations using first-step analysis\n",
    "        for i in range(n_states):\n",
    "            for k in range(n_states):\n",
    "                if k == target:\n",
    "                    continue\n",
    "                A[i, k] -= P[i, k]\n",
    "\n",
    "        # Solve linear system\n",
    "        m = np.linalg.solve(A, b)\n",
    "\n",
    "        # Extract hitting time from start_state\n",
    "        hit_theor[target] = m[start_state]\n",
    "\n",
    "    return hit_theor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250cf14",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e017a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1_main():\n",
    "    print(\"\\n=== Problem 1: Markov chain estimation + hitting times ===\")\n",
    "\n",
    "    # 1) Estimate P\n",
    "    P_hat = comp_transition_matrix(X_t, N_states)\n",
    "    print(\"Estimated P_hat:\\n\", np.round(P_hat, 3))\n",
    "\n",
    "    # 2) Validate\n",
    "    print(\"Is valid transition matrix?\", is_transition_matrix(P_hat))\n",
    "\n",
    "    # 3) Expected steps from given start state to all states\n",
    "    start_state = 0\n",
    "\n",
    "    # simulation\n",
    "    mc = hitting_times_sim(P_hat, start_state=start_state, n_sim=5000)\n",
    "\n",
    "    # Theory (linear system)\n",
    "    th = theoretical_hitting_times(P_hat, start_state=start_state)\n",
    "\n",
    "    # 4) Compare\n",
    "    df = pd.DataFrame({\n",
    "        \"target_state\": np.arange(N_states),\n",
    "        \"MC_estimate\": mc,\n",
    "        \"theoretical\": th,\n",
    "        \"abs_diff\": np.abs(mc - th),\n",
    "    })\n",
    "    print(\"\\nComparison table:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a45403",
   "metadata": {},
   "source": [
    "PROBLEM 2: Cost-Sensitive Classification\n",
    "\n",
    "You are given a binary classification problem for fraud detection.\n",
    "\n",
    "Class labels:\n",
    "\n",
    "    y = 1 => fraud\n",
    "\n",
    "    y = 0 => ok\n",
    "\n",
    "\n",
    "\n",
    "The costs of classification outcomes are:\n",
    "    TP = 0, TN = 0, FP = 100, FN = 500\n",
    "\n",
    "Tasks:\n",
    "1. Train an SVM classifier.\n",
    "2. Compute classification costs at a fixed threshold (0.5).\n",
    "3. Evaluate total cost for multiple probability thresholds.\n",
    "4. Find the threshold that minimizes total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250243</td>\n",
       "      <td>-0.863902</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380736</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>-0.559577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126431</td>\n",
       "      <td>2.055912</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806991</td>\n",
       "      <td>2.104160</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>-0.437259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3  fraud\n",
       "0 -0.250243 -0.863902 -0.307019      0\n",
       "1 -0.380736  0.018756 -0.559577      0\n",
       "2  1.126431  2.055912  0.973126      1\n",
       "3  0.806991  2.104160 -0.211368      1\n",
       "4  0.059649  0.652374 -0.437259      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Generate a simple fraud dataset as a single table. The table contains:\n",
    "        - numerical features: x1, x2, x3\n",
    "        - binary target column: fraud (1 = fraud, 0 = legitimate)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Target variable\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "\n",
    "    # Features\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "\n",
    "    #  fraud cases are shifted\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"fraud\": fraud,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "fraud_data = generate_fraud_table()\n",
    "\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031231e8",
   "metadata": {},
   "source": [
    "Fill in the methods in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d03aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    \"\"\"\n",
    "    Split a data table into training and test sets.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # implement splitting\n",
    "    # first, decide what are features and what are target \n",
    "    # Features and target\n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train.to_numpy(), y_test.to_numpy()\n",
    "\n",
    "\n",
    "def fit_linear_svm(fraud_data):\n",
    "    \"\"\"\n",
    "    Fit a linear SVM classifier.\n",
    "\n",
    "    Args: data table\n",
    "\n",
    "    Returns:\n",
    "        predicted labels of length len(y_test) \n",
    "    \"\"\"\n",
    "    # define our model\n",
    "    clf = LinearSVC(\n",
    "        C=1.0,\n",
    "        max_iter=10_000,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # split the data into trian and test:\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    #   Fit the SVM using X_train and y_train and predict the label using y_test. return y_pred\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN.\n",
    "    \"\"\"\n",
    "    \n",
    "    TP_est, TN_est, FP_est, FN_est = 0,0,0,0 \n",
    "    \n",
    "    # Here you Ccmpute TP, TN, FP, FN.\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    TP_est = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "    TN_est = int(np.sum((y_true == 0) & (y_pred == 0)))\n",
    "    FP_est = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "    FN_est = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "    \n",
    "    return {\"TP\": TP_est, \"TN\": TN_est, \"FP\": FP_est, \"FN\": FN_est}\n",
    "\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN.\n",
    "\n",
    "    Inputs:\n",
    "        y_true : array-like : True class labels (0 or 1)\n",
    "        y_pred : array-like: Predicted class labels (0 or 1)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with counts: TP, TN, FP, FN \n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize counters (not strictly necessary, but improves readability)\n",
    "    TP_est, TN_est, FP_est, FN_est = 0, 0, 0, 0\n",
    "\n",
    "    # Convert inputs to numpy arrays and ensure integer type\n",
    "    # This allows vectorized logical comparisons\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    # True Positives (TP):\n",
    "    # Model predicts 1 AND the true label is 1\n",
    "    TP_est = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "\n",
    "    # True Negatives (TN):\n",
    "    # Model predicts 0 AND the true label is 0\n",
    "    TN_est = int(np.sum((y_true == 0) & (y_pred == 0)))\n",
    "\n",
    "    # False Positives (FP):\n",
    "    # Model predicts 1 BUT the true label is 0\n",
    "    # (Type I error)\n",
    "    FP_est = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "\n",
    "    # False Negatives (FN):\n",
    "    # Model predicts 0 BUT the true label is 1\n",
    "    # (Type II error)\n",
    "    FN_est = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "    # Return results in a dictionary for convenient access\n",
    "    return {\"TP\": TP_est, \"TN\": TN_est, \"FP\": FP_est, \"FN\": FN_est}\n",
    "\n",
    "\n",
    "def total_cost(counts):\n",
    "    \"\"\"\n",
    "    Compute total cost from confusion counts.\n",
    "\n",
    "    \"\"\"\n",
    "    # Multiply counts by costs and sum\n",
    "    total_cost = (counts[\"TP\"] * costs[\"TP\"]) \n",
    "    + (counts[\"TN\"] * costs[\"TN\"]) \n",
    "    + (counts[\"FP\"] * costs[\"FP\"]) \n",
    "    + (counts[\"FN\"] * costs[\"FN\"])\n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "# evaluate how the classification cost changes when you change the decision threshold.\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    \"\"\"\n",
    "    Evaluate total cost for a range of thresholds.\n",
    "    \n",
    "    Here, clf is your trained SVM classifier\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # note: here, I define y_probs to be just a decision function. Think: does it need to be calibrated to be used in this problem?\n",
    "    y_probs = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # 1) compute the prediction for a chosen theshold\n",
    "        y_pred = (y_probs >= t).astype(int)\n",
    "\n",
    "        # 2) Confusion matrix counts  (previoulsy implemented by you)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "\n",
    "        # 3) Total cost (previoulsly implemented by you)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        # 4) Store results\n",
    "        results.append({\n",
    "            \"threshold\": t,     # \"threshold\": float(t),\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost, # \"total_cost\": float(cost),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c44a4",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4235863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    df = fraud_data\n",
    "\n",
    "    print(\"Dataset head:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "    # split in train and test:\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    # Fit linear SVM\n",
    "    clf = fit_linear_svm(df)\n",
    "\n",
    "    # thresholds\n",
    "    thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "    df_results = sweep_thresholds(\n",
    "        y_test,\n",
    "        clf,\n",
    "        X_test,\n",
    "        thresholds,\n",
    "    )\n",
    "\n",
    "    print(\"Threshold sweep results:\")\n",
    "    print(df_results)\n",
    "\n",
    "    # 6) Identify optimal threshold\n",
    "    best_row = df_results.loc[df_results[\"total_cost\"].idxmin()]\n",
    "    print(\"Optimal threshold:\", best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8baea",
   "metadata": {},
   "source": [
    "PROBLEM 3: Confidence estimation of the cost\n",
    "\n",
    "In Problem 2, you trained a classifier, selected a decision threshold, evaluated its performance on a test set, and computed the cost\n",
    "\n",
    "In this problem, you will quantify the uncertainty of this estimated cost. Each observation in the test set produces a cost depending on the\n",
    "classification outcome:\n",
    "\n",
    "    TN: 0\n",
    "   \n",
    "    FP: 100\n",
    "\n",
    "    TP: 0\n",
    "\n",
    "    FN: 500\n",
    "\n",
    "Thus, the cost per observation is a bounded random variable taking\n",
    "values in the interval [0, 500].\n",
    "\n",
    "Tasks:\n",
    "1. Compute the average cost per observation on the test set.\n",
    "2. Use Hoeffdingâ€™s inequality to construct a 95% confidence interval\n",
    "   for the true expected cost of the classifier.\n",
    "3. Interpret the resulting interval:\n",
    "   - What does it say about the reliability of your estimate?\n",
    "   - Is the interval likely to be tight or conservative? Why?\n",
    "\n",
    "You may assume that test observations are independent and identically\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bfb275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_observation_cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute per-observation cost vector.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "\n",
    "    c = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "    # FP: y=0, pred=1 -> 100\n",
    "    c[(y_true == 0) & (y_pred == 1)] = costs[\"FP\"]\n",
    "\n",
    "    # FN: y=1, pred=0 -> 500\n",
    "    c[(y_true == 1) & (y_pred == 0)] = costs[\"FN\"]\n",
    "\n",
    "    # here, you will compute the average cost using the test set\n",
    "    cost_avg = np.mean(c)\n",
    "\n",
    "\n",
    "    # TP/TN -> 0 already\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hoeffding_ci(per_obs_costs, mean, n, a, b, delta=0.05):\n",
    "    \"\"\"\n",
    "    Hoeffding confidence interval\n",
    "    \"\"\"\n",
    "    # Step 1: deterministic costs per observation\n",
    "    c = per_obs_costs\n",
    "\n",
    "    # Step 2:   average cost\n",
    "    mean_cost = np.mean(c)\n",
    "\n",
    "    # Step 3: construct a Hoeffding intevral of the estimated cost\n",
    "\n",
    "    n = int(c.size)\n",
    "\n",
    "    # Hoeffding: P(|mean - E| >= eps) <= 2 exp(-2 n eps^2 / (b-a)^2)\n",
    "\n",
    "    eps = (b - a) * np.sqrt(np.log(2.0 / delta) / (2.0 * n))\n",
    "\n",
    "    lower = max(a, mean_cost - eps)\n",
    "    upper = min(b, mean_cost + eps)\n",
    "\n",
    "    ci = (lower,upper)\n",
    "    \n",
    "    \n",
    "    return ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1a079",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Check Exam template tutoring for discussion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
